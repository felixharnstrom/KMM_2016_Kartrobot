\documentclass[a4paper,11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[swedish]{babel}
\usepackage[top=1in,bottom=1in,left=1in,right=1in,headsep=.5in]{geometry}
\usepackage{hyperref}
\usepackage{graphicx}

\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\usepackage[yyyymmdd,hhmmss]{datetime}
\renewcommand{\dateseparator}{-}

\usepackage{mathptmx}    %Times Roman font
\usepackage{helvet}    %Helvetica, served as a model for arial
\usepackage{anyfontsize}

\usepackage[tocgraduated]{tocstyle}
\usetocstyle{allwithdot}

\usepackage[titletoc,title]{appendix}

\usepackage[backend=bibtex,style=authoryear,maxcitenames=2,maxbibnames=9]{biblatex} %Harvard-style citations
\setlength{\bibitemsep}{\baselineskip}	%vertical space between bibliography items

\usepackage{fancyhdr}
\fancypagestyle{intro}{
    \fancyhf{}
    \fancyhead[C]{\LIPSprojekttitel}
    \fancyhead[R]{\today} 
    \fancyfoot[L]{\LIPSkursnamn \\ \LIPSdokumenttyp}
    \fancyfoot[C]{\phantom{text}\roman{page}}
    \fancyfoot[R]{\LIPSprojektgrupp \\ \LIPSgruppepost} 
    \renewcommand{\headrulewidth}{0.4pt}
    \renewcommand{\footrulewidth}{0.4pt}}
\fancypagestyle{content}{
    \fancyhf{}
    \fancyhead[C]{\LIPSprojekttitel}
    \fancyhead[R]{\today} 
    \fancyfoot[L]{\LIPSkursnamn \\ \LIPSdokumenttyp}
    \fancyfoot[C]{\phantom{text}\thepage}
    \fancyfoot[R]{\LIPSprojektgrupp \\ \LIPSgruppepost} 
    \renewcommand{\headrulewidth}{0.4pt}
    \renewcommand{\footrulewidth}{0.4pt}}

\usepackage{titlesec}
\titleformat{\section}
    {\normalfont\sffamily\Large\bfseries}
    {\thesection}{1em}{}
\titleformat{\subsection}
    {\normalfont\sffamily\large\bfseries}
    {\thesubsection}{1em}{}
\titleformat{\subsubsection}
    {\normalfont\sffamily\bfseries}
    {\thesubsubsection}{1em}{}

\newcommand{\LIPSartaltermin}{2016/HT}
\newcommand{\LIPSkursnamn}{TSEA29}
\newcommand{\LIPSprojekttitel}{Kartrobot}
\newcommand{\LIPSprojektgrupp}{Grupp 1}
\newcommand{\LIPSgruppepost}{\href{mailto:kmm_2016_grupp1@liuonline.onmicrosoft.com}{{\small kmm\_2016\_grupp1@liuonline.onmicrosoft.com}}}
\newcommand{\LIPSgrupphemsida}{}
\newcommand{\LIPSkund}{ISY, Linköpings universitet, 581\,83 Linköping}
\newcommand{\LIPSkundkontakt}{Mattias Krysander, 013-282198, matkr@isy.liu.se}
\newcommand{\LIPSkursansvarig}{Tomas Svensson, 013-281368, Tomas.Svensson@liu.se}
\newcommand{\LIPShandledare}{Olov Andersson, 013-282658, olov@isy.liu.se}
\newcommand{\LIPSdokumenttyp}{Designspecifikation}
\newcommand{\LIPSredaktor}{Jag måste skriva något här för att kunna kompilera}
\newcommand{\LIPSversion}{0.1}
\newcommand{\LIPSgranskare}{}
\newcommand{\LIPSgranskatdatum}{}
\newcommand{\LIPSgodkannare}{}
\newcommand{\LIPSgodkantdatum}{}

\addbibresource{bibliography.bib}
\input{LIPS.tex}

\begin{document}

\pagestyle{intro}
\LIPStitelsida
\clearpage
\begin{LIPSprojektidentitet}
    \LIPSgruppmedlem{Hannes Haglund}{Designansvarig mjukvara (MV)}{hanha265@student.liu.se}
    \LIPSgruppmedlem{Felix Härnström}{Projektledare (PL)}{felha423@student.liu.se}
    \LIPSgruppmedlem{Jani Jokinen}{Leveransansvarig (LEV)}{janjo273@student.liu.se}
    \LIPSgruppmedlem{Silas Lenz}{Testansvarig (TST)}{sille914@student.liu.se}
    \LIPSgruppmedlem{Daniel Månsson}{Designansvarig hårdvara (HV)}{danma344@student.liu.se}
    \LIPSgruppmedlem{Emil Norberg}{Dokumentansvarig (DOK)}{emino969@student.liu.se}
\end{LIPSprojektidentitet}

\clearpage
\renewcommand{\familydefault}{\sfdefault}	%Sans-serif
\normalfont
\tableofcontents
\renewcommand{\familydefault}{\rmdefault}	%Back to serifs
\normalfont
\clearpage
\begin{LIPSdokumenthistorik}
    \LIPSversionsinfo{0.1}{2016-09-22}{Första utkastet}{}{}
\end{LIPSdokumenthistorik}
\clearpage
\setcounter{page}{1}
\pagestyle{content}

\section{Inledning}

I detta dokument redogörs idéer om hur robotens delsystem kan konstrueras. Det är ej bindande, utan tjänar snarare som en grov kompass inför projektets implementation och planering. Skissen används för att avgöra vilka moduler som ingår och hur arbetet kan delas upp.

\begin{figure}[h!]
    \makebox[\textwidth][c]{\includegraphics[width=1\textwidth]{overview.png}}
    \caption{Systemet i dess omgivning.}
    \label{fig:overview}
\end{figure}

\newpage
\section{Översikt av systemet}
Systemet är uppbyggt av tre separata moduler, samt en extern PC, enligt figur \ref{fig:modules}. Dessa delsystem kommunicerar med varandra, och med respektive moduls externa hårdvara. Ett mer detaljerat blockschema finns till varje modul, samt i sin helhet i figur \ref{fig:modulesDetailed}.
\begin{figure}[h!]
    \makebox[\textwidth][c]{\includegraphics[width=1\textwidth]{modules.png}}
    \caption{Modulöversikt.}
    \label{fig:modules}
\end{figure}

\newpage

\section{Sensorenhet}
Sensorenheten har i uppgift att läsa in sensordata och omvandla den till ett läsligt format. Den innehåller en processor av modellen ATmega1284, flera IR-sensorer, en lasersensor, samt gyro.

IR-sensorerna används primärt för navigering, så att roboten kan köra i en rak linje längs en vägg. Lasersensorn används för skanning av rummet. Med hjälp av gyrot går det att hålla koll på robotens rotation.
Se figur \ref{fig:unitSensor} för en övergripande systemskiss för sensorenheten.

\begin{figure}[h!]
	\makebox[\textwidth][c]{\includegraphics[width=0.6\textwidth]{sensorenhet.png}}
	\caption{Översikt över sensorenheten.}
	\label{fig:unitSensor}
\end{figure}

\subsection{Hårdvara}

\subsubsection{Processor}
ATmega1284 används som processormodell, då den är kraftfull utan att ta det till överdrift. Antalet pinnar, A/D-omvandlare, interrups samt UART-enheter som processorn har räcker för samtliga sensorer och kommunikationsbussar.

\subsubsection{IR-sensorer} \label{sssec:sonicsensors}
Det placeras två stycken IR-sensorer av modell GP2D120 på både höger och vänster sida om roboten (för totalt fyra), samt en på baksidan. För avståndsmätning framåt används LIDARn. Dessa sensorer används för navigering och positionsuppskattning. Med hjälp av de dubbla IR-sensorerna på vardera sida kan det avgöras ifall roboten åker parallelt med väggen. Dessa behöver en A/D-omvanlare var, som är inbyggd i processorn ATmega1284. Se kapitel \ref{ssec:sensorInterface}. Sensorerna kan effektivt mäta avstånd inom intervallet 4 till 30 cm vilket räcker, då roboten är tänkt att följa en vägg och köra inom ett rutnät på 40x40cm.

\subsubsection{LIDAR lite v2} \label{sssec:lidar}
LIDAR Lite v2 är en lasersensor som används för mätningar som kräver bättre noggranhet. Komponenten kommunicerar via en trigger-pin och PWM-output.

LIDARn används också som en sensor framåt, för attt avgöra ifall robotten kan fortsätta att köra.

Sensorn monteras på toppen av roboten - ovanpå ett roterande servo, som specificeras i större detalj i kapitel \ref{ssec:servomotor}. Detta för att kunna mäta avstånd i flera vinklar utan att snurra roboten.

\subsubsection{IMU} \label{sssec:imu}
MLX90609 är ett gyro som används via en analog ingång. Den ger oss rotationen kring z-axeln, som användas för att beräkna robotens riktning i rummet under svängar.

\subsubsection{Komponentbudget}
Här följer en lista på all hårdvara som detta delsystem kräver.

%TODO Uncomment after rebase; hardware list is not yet defined in LIPS.tex
%\begin{HardwareList}
%\hardware{Atmega1284p}{Mikroprocessor med 44 pinnar (inklusive 8 A/D-omvandlare).}{1} %TODO: Eventuellt LP-filter till AVCC-porten. Finns ej i Anders föreläsning, men i många andra.
%\hardware{IQEXO-3}{Occilator för Atmega-klockan, med standardfrekvens 16MHz}{1}
%\hardware{GP2D120}{IR-sensor.}{5}
%\hardware{Kondensator}{Till LP-filter för IR. Storlek bestäms av frekvensen på störningarna.}{5}
%\hardware{Resistans}{Till LP-filter för IR. Storlek bestäms av frekvensen på störningarna.}{5}
%\hardware{LIDAR lite v2}{Avancerad lasersensor.}{1}
%\hardware{Resistans}{Separation av trigger och monitor för LIDAR. 1k.}{1}
%\hardware{Kondensator}{Störningsreducering av LIDAR. 680uF.}{1}
%\hardware{MLX90609}{Gyro.}{1}
%\hardware{Kondensator}{Störningsreducering av gyro. 1uF. Datablad rekommenderar X5R eller X7R med minsta spänning 10V.}{2}
%\hardware{Kapacistans}{Störningsreducering av gyro. 0.1uF. Datablad rekommenderar X5R eller X7R med minsta spänning 25V.}{1} % TODO: Finns en till typ frivillig, se datablad. Finns inritad i schemat.
%\end{HardwareList}

\subsection{Mjukvara}

Koden skrivs i C, och ska följa standarden specificerad i bilaga \ref{sec:cstandard}.

Programmet omvandlar sensordata till ett mer läsligt format, och skickar det vidare (se kapitel \ref{ssec:sensorInterface}), samt tar emot instruktioner om att läsa av en viss sensor. 

Sensorenheten ska kontinuerligt läsa av sensorerna, på detta sätt går det smidigt att även kolla baklänges på tidigare avläsningar. Att läsa av sensorerna kontinuerligt gör det möjligt för sensormodulen att vara medveten ifall roboten följer en vägg eller inte. Sensorenheten kommer att ha en interrupt, som ger möjligheten för den att läsa av sensorer direkt när en avläsning begärs.

% TODO Avläsningsinstruktioner? Menas kommandon som: ``Tja, jag ser gärna detta avläst''? Bör förtydligas och utvecklas. - Tillräckligt?

% TODO Denna sektionen känns i största allmänhet alldeles för tunn. Utveckla mer. Lägg till flödesscheman.

\subsection{Gränssnitt} \label{ssec:sensorInterface}
Sensorenheten ska kommunicera med alla sensorer och skicka vidare utdata. Sensorenheten tar emot uppmaningar om att starta en avläsning via samma UART-buss som används för att rapportera mätvärden vidare.

% TODO Utveckla den här sektionen. Nämn inte I2C; det används inte. Jag misstänker att det mesta av texten nedan bara är rakt ur systemskissen.

\subsubsection{LIDAR}
LIDAR kommer använda avläsningstriggers och PWM via en gemensam pin på sensorn. På Atmega-sidan delas denna upp i två pinnar med en resistor på triggersignalen som gör att LIDARns signaler får prioritet. PWM-signalen kopplas ett avbrott för att mäta dess längd, som används för att beräkna avståndet.

Under körning kommer mätdatan från LIDAR att användas för att avgöra om roboten kan fortsätta framåt.

\subsubsection{Gyro}
MLX90609 stödjer avläsning via en analog pinne samt via SPI. Vi använder analog avläsning. Alltid när roboten vänder görs en avläsning av gyrot, för att avgöra vinkeln.  

Gyrot använder avläsningstiggers, för att enbart göra avläsningar när information om vändning behövs.

\subsubsection{IR-sensorer}
IR-sensorerna använder en analog utgång som varierar i enlighet med avståndet efter en ickelinjär kurva. Denna signal har störningar som måste filtreras ut, med hjälp av LP-filter.

IR-sensorer kommer att genomföra kontinuerligt mätningar för att avgöra ifall roboten åker rakt fram. Det finns också möjlighet till avläsningstriggers, så att när det kommer en begäran om avläsning kan detta genomföras ögonblickligen.

\subsubsection{Utvärden/Input}
En UART-buss används där den inbyggda UART-hårdvaran utnyttjas. Via denna buss tas avläsningsinstruktioner emot och sensordata skickas.

\newpage
\section{Styrenhet} \label{sec:system2}
Styrenheten är ansvarig för all logik och funktionalitet för robotens lågnivåstyrning. Styrenheten är länken mellan alla styrkommandon och motorerna. Se figur \ref{fig:unitMotorcontroller} för en övergripande systemskiss för styrenheten.

\begin{figure}[h!]
    \makebox[\textwidth][c]{\includegraphics[width=0.6\textwidth]{styrenhet.png}}
    \caption{Översikt över styrenheten.}
    \label{fig:unitMotorcontroller}
\end{figure}
\noindent \begin{small}
    * Om I\textsuperscript{2}C används krävs även en logic level converter mellan 5V och 3V3 på dessa platser.
\end{small}
\subsection{Hårdvara}

\subsubsection{Processor}

\paragraph{Alternativ 1}
Processormodellen ATmega1284.

\paragraph{Alternativ 2}
Processormodellen AtMega1284's mindre syskon, ATmega16. Denna är inte lika kraftfull som den förstnämnda, men bör vara kapabel till att utföra dess givna jobb. Om UART används för både kommunikation mellan moduler och till servon räcker inte denna till, då endast en hårdvaru-UART finns tillgänglig.

\subsubsection{Servo/steppermotor} \label{ssec:servomotor}
På toppen av roboten ska en sensor (se \ref{sssec:lidar}) vara monterad ovanpå en roterande servo, för att tillåta sikt i flera riktningar utan att behöva rotera hela roboten. Typen av servomotor specificeras här.

\paragraph{Alternativ 1}
Servomotorn AX-12(+/A) används. Denna har både ett ''vanligt'' läge, och ett så kallat ''wheel''-läge som tillåter fri 360 graders rotation. Det förstnämnda tillåter oss att göra mycket exakta rotationer, men förhindrar oss från att svänga runt mer än 300 grader. Vi slipper potentiellt felaktiga värden, men kan inte titta rakt bakom oss. Då detta inte är ett stort problem används lämpligen det vanliga läget. Servot använder, enligt vissa källor, 9-12V men klarar sig enligt andra med ner emot 7V. Kan alltså eventuellt kräva en step-up-krets från ~7V2 till 9-12V.
% http://support.robotis.com/en/techsupport_eng.htm#product/dynamixel/ax_series/dxl_ax_actuator.ht

\paragraph{Alternativ 2}
En servo med liknande specifikationer kring rotationsmöjligheter och noggrannhet, men med lägre spänning, och gärna ett mindre komplext protokoll, som PWM, används.

% Alternativ 3: Stepper motor med driver.

\subsubsection{Hjulmotorer}
Totalt fyra motorer finns monterade på chassit för hjulstyrning. Detta chassi går under namnet \cite{terminator}, och de fyra DC-motorerna styrs parvis (höger sida och vänster sida) med hjälp av en PWM-signal samt en rotationsriktningssignal per motorpar.

\subsection{Mjukvara}

Koden ska vara skriven i C, och ska följa standarden specificerad i bilaga \ref{sec:cstandard}.

\subsection{Gränssnitt} \label{ssec:controllInterface}

\subsubsection{Styrsignaler samt styrdata}

\paragraph{Alternativ 1}
Implementera en extra UART-buss som endast går mellan styrenheten och kommunikationsenheten. Se \ref{ssec:brainInterface} för mer detaljer om för och nackdelar.

\paragraph{Alternativ 2}
I\textsuperscript{2}C-bussen som eventuellt används för att kommunicera med LIDAR:n och gyron kan utnyttjas, med även styrenheten som slav. Enheten som tar emot data från/skickar data till styrenheten får istället ta över rollen som master. Se \ref{ssec:brainInterface} för mer detaljer om för och nackdelar.

\newpage
\section{Kommunikations- och kontrollenhet} \label{sec:system3}
Kommunikations-enheten kommunicerar med de andra modulerna på roboten samt med den bärbara datorn. I denna modul ingår också kontrollenheten, som gör beräkningar relaterat till både det manuella och det autonoma läget. Se figur \ref{fig:unitBrain} för en övergripande systemskiss för kommunikations- och kontrollenheten.
\begin{figure}[h!]
    \makebox[\textwidth][c]{\includegraphics[width=1\textwidth]{brain.png}}
    \caption{Översikt över kommunikations- och kontrollenheten.  }
    \label{fig:unitBrain}
\end{figure}
\noindent \begin{small}
* Om I\textsuperscript{2}C används krävs även en logic level converter mellan 5V och 3V3 på dessa platser.
\end{small}


\subsection{Hårdvara}

\subsubsection{Datormodell}
Då detta delsystem har hand om relativt tunga beräkningar används en Raspberry Pi 3. Vi utnyttjar Raspberryns inbyggda blåtand för trådlös kommunikation.

\subsection{Mjukvara}
Koden ska vara skriven i Python 3, och ska följa \cite{pep8}.

\subsubsection{Kommunikation}
Delsystemet är vad som i slutändan kontrollerar de olika delsystemen, och måste därför kunna skicka meddelanden mellan dessa. Den ska ha mjukvara för att kunna skicka meddelanden över de olika gränssnitten som den kopplas upp emot (se \ref{ssec:brainInterface}).

Förutom hårdvarugränssnitt ska den också kunna kommunicera med en extern PC (se \ref{sec:system4}) över blåtand, där den skickar debugdata och kartinformation, och tar emot kommandon vid manuell styrning. Mjukvara för blåtandskommunikation måste finnas.

För att hantera alla dessa meddelanden bör ett meddelandesystem implementeras. Detta görs lämpligen med en prioriterad kö, så att vissa meddelanden kan prioriteras över andra.

\subsubsection{Manuellt läge}
Roboten ska via en brytare kunna byta mellan ett autonomt och ett manuellt läge. I det manuella ska den ta emot kommandon från PC:n via blåtand (se \ref{sec:system4}) om hur den ska åka, mycket likt en radiostyrd bil. Mjukvara för att på ett korrekt sätt utföra dessa kommandon behövs.

\subsubsection{Kartritning}
Robotens huvuduppdrag i det autonoma läget är att skanna ett rum och rita en karta över det. Mjukvara för att omvandla skannerdata till ett tvådimensionellt rum, samt rutiner för att söka upp och skanna outforskade delar av rummet ska finnas.

\subsubsection{Ruttstyrning}
Roboten behöver kontinuerligt ta reda på, och leta sig till, outfoskade delar av rummet i det autonoma läget. En algoritm för att hitta ett lämpligt outforskat ställe, en för att hitta en väg dit, och en som skickar korrekta meddelanden till styrenheten (se \ref{sec:system2}) för att ta sig dit behövs.

\subsection{Gränssnitt} \label{ssec:brainInterface}

\paragraph{Alternativ 1}
Två UART-bussar används, som kopplas från kommunikations- och kontrollenhet till sensorenhet respektive styrenhet. Raspberry Pi 3 har ingen inbyggd UART som kan användas utan bland annat låsa klockfrekvensen och använda spänningsomvandlare från 5v till 3v3, och har dessutom bara en ledig om blåtand används samtidigt. Istället kan två 5 volts-kompatibla USB till UART-moduler, exempelvis CH340G eller liknande enhet, användas. Nackdelen är att UART måste implementeras på alla moduler, vilket dock verkar relativt trivialt. % TODO: LiU har förmodligen inte samma saker som kina (https://www.aliexpress.com/item/CH340-Serial-Converter-USB-To-TTL-6PIN-Module-Upgrade-Small-Plate-for-PRO-mini-Instead-of/1856263846.html). CP2102 kanske (om den är 5v-kompatibel).


\paragraph{Alternativ 2}
I\textsuperscript{2}C via samma buss som eventuella sensorer, där kommunikationsenheten agerar master. Detta gör att vi slipper implementera flera UART-bussar, men gör att både sensorer och tre moduler behöver samsas på samma buss. Har även nackdelen att kod i kommunikationsenheten behöver modifieras när sensoruppsättningen förändras, vilket minskar modulariteten.
Vid kommunikationsenheten behöver dessutom en logic level shifter användas, då Raspberry Pi använder 3v3 och övriga moduler 5v. Om I\textsuperscript{2}C inte används för LIDAR eller IMU har en onödigt komplicerad buss utvecklats i onödan.

\newpage
\section{ Mjukvara på PC} \label{sec:system4}
Detta delsystem kommunicerar med Kommunikations- och kontrollenheten (se \ref{sec:system3}) för att ta emot diagnostisk data, den upptäckta kartan, samt ge instruktioner vid manuellt läge. Se figur \ref{fig:unitPC} för en övergripande systemskiss för PC-mjukvaran.

\begin{figure}[h!]
    \makebox[\textwidth][c]{\includegraphics[width=0.4\textwidth]{PC.png}}
    \caption{Översikt över PCn.}
    \label{fig:unitPC}
\end{figure}
\subsection{Hårdvara}
En godtycklig PC med Python-3-support, skärm, tangentbord, och blåtandsmodul.

\subsection{Mjukvara}

Koden ska vara skriven i Python 3, och ska följa \cite{pep8}.

Då grafiska element (snarare än kommandoraden) måste utnyttjas så införskaffas ett lämpligt grafikbibliotek.

\subsubsection{Input}
PC-mjukvaran tar emot sensordata, styrdata och kartdata från kommunikationsenheten via blåtand. Den tar också emot instruktioner från mus och tangentbord. 

\subsubsection{Output}
Mjukvaran skickar styrkommandon samt uppmaning om att läsa av sensorerna till roboten i dess manuella läge. Den kan också skicka kommandon om att växla mellan autonomt och manuellt läge, som då går före den fysiska brytaren på roboten.

Informationen som tas emot från roboten presenteras i ett grafiskt gränssnitt.

\subsection{Gränssnitt} \label{ssec:PCInterface}

PC:n utnyttjar, som omnämnt, en blåtandsmodul.

\newpage
\begin{appendices}

\section{Detaljerat blockschema}
% TODO: Riktig titel
\begin{figure}[h!]
    \makebox[\textwidth][c]{\includegraphics[width=0.85\textwidth]{modules_detail.png}}
    \caption{Detaljerat blockschema över systemet.}
    \label{fig:modulesDetailed}
\end{figure}

\noindent \begin{small}
    * Om I\textsuperscript{2}C används krävs även en logic level converter mellan 5V och 3V3 på dessa platser.\\
    ** 5V på Atmega-sidan, 3V3 krävs av sensorn.
\end{small}

\section{C-standard} \label{sec:cstandard}
Som kodstandard för C används \cite{cstandard} med några smärre tillägg och ändringar:

\begin{itemize}
    \item Indenteringar sker med exakt fyra stycken mellanslag.
    \item Namn på funktioner, typedef, variabler, strukter, unioner, och enums ska vara i lower camel case.
    \item Namn på \#define's, enum-konstanter, och macrofunktioner ska vara i all-caps med ord separerade av underscore.
    \item Typedef:ade namn ska avslutas med "\_t".
    \item Globala namn ska \textit{ej} påbörjas med ett prefix som identiferar vilken modul de tillhör.
    \item Dokumentationskommentarer för funktioner och dylikt ska inledas med "/*" följt av tom rad, med textrader inledda med "{ }* ". Hela kommentaren avslutas med en rad som endast innehåller "{ }*/".
\end{itemize}

\end{appendices}

\clearpage
\addcontentsline{toc}{section}{Referenser} %append references section at this location to TOC
\printbibliography
\end{document}
